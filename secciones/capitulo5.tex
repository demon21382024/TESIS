\chapter{MARCO METODOLÓGICO}

% \noindent
% \setlength{\parindent}{1.25cm} % Asegura la sangría de 1.25 cm en el primer párrafo del capítulo

La metodología propuesta se enmarca específicamente en la re-identificación de personas basada en la marcha (\textit{Gait Recognition}). Se adoptará un enfoque híbrido que combina el aprendizaje auto-supervisado (SSL) y el aprendizaje supervisado, mediante \textit{Fine-Tuning}, para desarrollar un modelo robusto y generalizable, capaz de superar las limitaciones inherentes a la variabilidad de la apariencia y la escasez de datos etiquetados en escenarios de videovigilancia (\cite{Huang2025PersonViT, Lee2023GaitParse}).

\begin{comment}
Este enfoque metodológico se divide rigurosamente en tres áreas principales: La justificación y el diseño arquitectónico de la fusión \textit{Multi-Modal}, el protocolo de pre-procesamiento de datos de marcha, y la estrategia de entrenamiento híbrido; culminando en un diseño experimental detallado para la validación y el análisis de ablación.
\end{comment}

El modelo implementado en la presente investigación utiliza un \textit{backbone} convolucional ligero diseñado específicamente para operar sobre siluetas estáticas. Este extractor basado en \textit{CNN} transforma cada imagen en un vector de características, sin incorporar módulos explícitos de atención o mecanismos temporales. Sobre este backbone se añade una capa completamente conectada que actúa como cabeza métrica, encargada de generar un embedding normalizado que permite medir distancias entre identidades.

\section{Diseño híbrido}

La estrategia de doble etapa es el pilar de este trabajo. Se justifica al considerar que el entrenamiento de modelos requieren un volumen de datos masivo para aprender representaciones robustas, una necesidad que la anotación manual supervisada no puede satisfacer eficientemente (\cite{Huang2025PersonViT, Lee2023GaitParse}).

\section{Fase I: Fundación del Conocimiento – Pre-entrenamiento Auto-Supervisado (SSL)}

La primera fase de la metodología se sustenta en el \textit{Aprendizaje Auto-Supervisado} (\textit{Self-Supervised Learning}, SSL). Este paradigma elimina la dependencia de etiquetas humanas al generar su propia señal de supervisión a partir de la estructura intrínseca de los datos. El propósito de esta fase no es resolver la tarea final, sino construir un \textit{modelo base} (\textit{backbone}) capaz de desarrollar una comprensión profunda y generalizable de las características visuales relevantes.  

\begin{comment}
El proceso se basa en la formulación de \textit{tareas de supervisión derivadas directamente de los datos}, las cuales, de acuerdo con la literatura especializada en visión por computador, pueden clasificarse en dos enfoques metodológicos principales:
\end{comment}

El pre-entrenamiento autosupervisado implementado adopta un enfoque basado en predicción de transformaciones. En esta fase, el modelo recibe imágenes de siluetas a las que se les aplican transformaciones geométricas simples y el objetivo consiste en que el modelo identifique cuál transformación fue aplicada. Este mecanismo obliga al backbone a aprender patrones estructurales relevantes del cuerpo humano y de la forma general de la marcha, sin necesidad de etiquetas. Aunque este enfoque es más simple que métodos más avanzados como el enmascaramiento de patches o las \textit{contrastive losses}, resulta adecuado para una tesis de pregrado y suficiente para producir representaciones útiles que posteriormente se especializan durante el entrenamiento supervisado.

\subsection{Enfoques Generativos (Reconstructivos)}

Este grupo de métodos se fundamenta en el principio de \textit{aprender prediciendo lo oculto}. Modelos como el \textit{Modelado de Imágenes Enmascaradas} (MIM) o su versión temporal, el \textit{Modelado de Secuencias Enmascaradas} (MSM), representan ejemplos característicos de este enfoque.  

En un contexto de \textit{reidentificación basada en la marcha} (\textit{Gait Re-ID}), el modelo no recibe la secuencia completa de siluetas. En su lugar, se le presenta una secuencia en la que ciertos fotogramas o parches se encuentran enmascarados aleatoriamente, y su tarea consiste en reconstruir las partes ausentes.  

La justificación metodológica de este enfoque radica en que, para reconstruir correctamente una porción faltante de un ciclo de caminata, el modelo debe aprender la estructura latente del movimiento humano, las relaciones espaciales entre las articulaciones y la dinámica temporal del desplazamiento. Este proceso impulsa al modelo a desarrollar \textit{representaciones locales y de alta resolución}, que capturan la estructura esencial del fenómeno analizado.  

\subsection{Enfoques Discriminativos (Contrastivos)}

Esta familia de métodos, ampliamente difundida por marcos como \textit{MoCo} y \textit{SimCLR}, se basa en el principio de \textit{aprender mediante comparación}. En lugar de reconstruir, el modelo de \textit{Aprendizaje Contrastivo} (\textit{Contrastive Learning}, CL) aprende a identificar qué vistas provienen de la misma instancia y cuáles no.  

Durante el entrenamiento, el modelo maximiza la similitud en el espacio de características entre dos vistas aumentadas de una misma imagen (denominadas \textit{pares positivos}) y, simultáneamente, minimiza la similitud con las demás imágenes del conjunto (los \textit{pares negativos}).  

El objetivo metodológico de este enfoque es fomentar el \textit{aprendizaje de invariancias}, de modo que el modelo genere representaciones robustas frente a transformaciones superficiales tales como ruido, recortes o cambios de iluminación, preservando únicamente la identidad semántica de cada instancia.  

La \textbf{selección entre un enfoque generativo (MIM) o discriminativo (CL)} constituye una decisión metodológica fundamental, ya que determina el tipo de sesgo inductivo introducido en el modelo.  
\begin{itemize}
    \item Los métodos contrastivos priorizan el aprendizaje de características distintivas, lo que resulta adecuado para tareas de \textit{reidentificación basada en la apariencia}.
    \item Los métodos generativos promueven la comprensión de estructuras comunes, lo cual es más apropiado para la \textit{reidentificación basada en la marcha (Gait Re-ID)}, donde la dinámica del movimiento actúa como la firma biométrica principal.
\end{itemize}

El \textbf{resultado de la Fase I} no es un modelo finalizado, sino un \textit{modelo base preentrenado} con pesos inicializados que capturan conocimiento visual relevante para el dominio. Esta inicialización supera ampliamente a una aleatoria o incluso a un pre-entrenamiento convencional en \textit{ImageNet}, proporcionando mayor eficiencia de entrenamiento y mejor capacidad de generalización, además de ayudar al modelo a evitar mínimos locales poco representativos en las fases posteriores.  

\section{Fase II: Especialización de la Tarea – Ajuste Fino (Fine-Tuning) Supervisado}

Una vez que el modelo ha adquirido una comprensión general de la forma y el movimiento a través del pre-entrenamiento auto-supervisado, se procede a su especialización en la \textit{tarea específica (downstream task)} de reidentificación. En esta fase, se incorporan los \textit{datos etiquetados}, los cuales tienen un costo más elevado, con el propósito de desarrollar la capacidad discriminativa del modelo.  

A diferencia de un problema de clasificación tradicional, el objetivo principal de esta fase es el \textit{aprendizaje métrico (metric learning)}, cuyo propósito es construir un \textit{espacio de características (feature space)} altamente discriminativo. En dicho espacio, las representaciones correspondientes a una misma identidad (intra-clase) deben agruparse de manera compacta, mientras que las representaciones de distintas identidades (inter-clase) deben mantenerse lo más separadas posible.  

El problema de reidentificación presenta una naturaleza dual: requiere gestionar una \textit{alta variabilidad intra-clase} (una misma persona puede variar en apariencia según el ángulo, la ropa o las condiciones de iluminación) y, al mismo tiempo, una \textit{baja variabilidad inter-clase} (distintas personas pueden parecerse entre sí). Para abordar esta dualidad, se emplea una \textit{estrategia de pérdidas híbridas}, compuesta por dos funciones complementarias:

\begin{itemize}
    \item \textbf{Pérdida de Identidad (Identity Loss):} Habitualmente implementada mediante \textit{Entropía Cruzada (Cross-Entropy Loss)}. Este componente considera la tarea como un problema de clasificación y promueve la coherencia de las representaciones intra-clase al agrupar todas las instancias de una misma identidad en una única representación consistente.
    
    \item \textbf{Pérdida Métrica (Metric Loss):} Generalmente implementada mediante \textit{Triplet Loss} o \textit{Contrastive Loss}. Esta función impone explícitamente un margen de separación entre identidades, penalizando al modelo cuando la distancia entre una muestra ancla y su correspondiente positivo no es significativamente menor que la distancia al negativo.
\end{itemize}

No obstante, este proceso de especialización conlleva un riesgo metodológico conocido como \textit{olvido catastrófico}, que ocurre cuando el reajuste excesivo sobre los nuevos datos etiquetados deteriora la robustez y la capacidad general adquiridas en la fase anterior.  

Para mitigar este efecto, se aplica la técnica de \textit{Ajuste Fino Diferencial (Differential Fine-Tuning)}, que sustituye la tasa de aprendizaje uniforme por un esquema \textit{asimétrico}, considerando la distinta naturaleza de los componentes del modelo:  

\begin{itemize}
    \item \textbf{Modelo Base (heredado de la Fase I):} Incluye las capas previamente entrenadas que contienen conocimiento estructural y dinámico. A este componente se le asigna una tasa de aprendizaje reducida, con el fin de preservar la robustez adquirida y permitir ajustes graduales sin comprometer la generalización.

    \item \textbf{Cabeza de Clasificación (introducida en la Fase II):} Comprende las capas añadidas para la clasificación de identidad o la proyección métrica. Dado que estas capas se inicializan desde cero, se les asigna una tasa de aprendizaje más alta, permitiendo una rápida adaptación a la tarea supervisada de identificación.
\end{itemize}

El ajuste fino supervisado se realiza aplicando un único valor de tasa de aprendizaje tanto al backbone como a la cabeza métrica, manteniendo asi una configuración simple y coherente con los recursos computacionales disponibles. Durante esta fase, el modelo optimiza una combinación de pérdidas, \textit{Cross Entropy} para reforzar la discriminación entre identidades y Triplet Loss para estructurar el espacio de embeddings de manera métrica.

\begin{comment}
\subsection{Estructura del modelo de fusión textit{Multi-Modal} }

El modelo implementa una arquitectura de doble rama y \textbf{Fusión a Nivel de Característica} (\textit{Feature-Level Fusion}) para explotar la complementariedad de las biometrías de apariencia y marcha. \cite{Purish2023GaitRecognition, Rao2024MSFFT}

\begin{itemize}
    \item \textbf{Rama de Marcha ($\vec{F_g}$):} Emplea un \textit{backbone} de Vision Transformer (ViT) o 3D Local CNN, pre-entrenado con SSL, para extraer las características cinemáticas. \cite{Purish2023GaitRecognition, Rao2024MSFFT}
    \item \textbf{Rama de Apariencia ($\vec{F_a}$):} Utiliza un extractor de características 2D (e.g., ResNet-50) para capturar señales visuales a corto plazo. 
    \item \textbf{Módulo de Fusión:} Combina las características mediante la **Concatenación Ponderada**, la cual ha demostrado ser efectiva para integrar información correlacionada. \cite{Rao2024MSFFT} La fórmula conceptual para el vector de característica final ($\vec{F}$) es:
    $$\vec{F} = [\vec{F_a}, \theta \cdot \vec{F_g}]$$
    El hiperparámetro $\theta$ se utiliza para aumentar el peso de la característica de marcha ($\vec{F_g}$), haciendo el sistema más robusto ante la variación de la vestimenta (condición CL), donde la información de apariencia falla. \cite{Zhou2024VersReID, Rao2024MSFFT}
\end{itemize}
\end{comment}

\subsection{Estrategia de muestreo - PKSampler}

Para el entrenamiento supervisado se emplea un muestreador PKSampler. Este muestreador selecciona en cada lote un conjunto fijo de identidades y un número fijo de imágenes por identidad, facilitando la construcción de ejemplos adecuados para la \textit{Triplet Loss}. Aunque su implementación es sencilla, cumple su función principal: asegurar variedad y equilibrio dentro de cada batch, elementos clave para un aprendizaje métrico estable.

\section{Adquisición y pre-procesamiento de datos}

La calidad y la estructura del conjunto de datos constituyen un componente determinante para el desempeño de los modelos de re-identificación de personas basados en Gait Recognition. En el presente trabajo, el proceso de adquisición y pre-procesamiento fue diseñado para ser coherente con los requerimientos del modelo híbrido implementado y con las características del dataset utilizado, que ya contiene siluetas humanas segmentadas. A continuación, se describe detalladamente el flujo seguido antes del entrenamiento.

\subsection{Adquisición y pre-procesamiento de datos}

Se proponen las siguientes bases de datos por su relevancia en la literatura revisada y su cobertura de las variantes clave:

\begin{table}[h]
    \centering
    \caption{Selección de Bases de Datos y Uso Metodológico}
    \label{tab:datasets}
    \begin{tabular}{l|p{3.5cm}|p{5cm}}
        \toprule
        \textbf{Dataset} & \textbf{Propósito Metodológico} & \textbf{Covariantes Clave} \\
        \midrule
        % OU-MVLP ($>10,000$ IDs) & Fase I: Pre-entrenamiento Auto-Supervisado (SSL) \cite{Huang2025PersonViT} & Multi-View \\
        CASIA-B (124 IDs) & Fase II: Ajuste Fino Supervisado y Evaluación Final \cite{Li2020SemiSupGait} & Ropa (CL), Carga (BG), Multi-View \\
        TUM-GAID & Validación complementaria de generalización \cite{Purish2023GaitRecognition} & Dirección de Caminata \cite{Han2021LocalitySGE} \\
        \bottomrule
    \end{tabular}
\end{table}

Debido a múltiples factores, para el presente proyecto hemos optado por el dataset de \textbf{CASIA-B} para poder trabajar con data etiquetada y no etiquetada deliberadamente.

\subsection{Pre-procesamiento de imágenes}

Dado que el dataset ya contiene siluetas limpias, el pre-procesamiento se enfoca únicamente en estandarizar las imágenes para que el modelo pueda procesarlas de forma eficiente.

\subsubsection{Conversión y normalización de intensidades}

Cada imagen se convierte a un tensor PyTorch y se normaliza siguiendo las convenciones estándar para redes convolucionales:

\begin{itemize}
    \item Los valores de píxel se escalan a (0,1)
    \item Se aplica normalización estadística por canal
    \item Las imagenes, aunque ya vienen por default en el dataset, se tratan como escala de grises.
\end{itemize}

Esta normalización es fundamental para asegurar la estabilidad en el proceso de optimización durante el entrenamiento.

\subsection{Normalización espacial}

Todas las imágenes se redimensionan a una resolución fija de: 64x64 pixeles. Ya que de esta forma se reduce el costo computacional, permitiendo que modelos \textit{CNN} y el módulo SSL sin necesidad de hardware potente extenro. Además, al estandarizar la entrada se facilita el aprendizaje del extractor de caracteriza. Por útltimo, también evita deformaciones significativas, ya que las siluetas tienen un alto nivel de contraste y estructura simple.

\subsection{Augmentación para Aprendizaje Autosupervisado}

Para la etapa de aprendizaje autosupervisado, el pre-procesamiento incorpora un conjunto específico de augmentaciones con el objetivo es generar dos versiones distintas de cada imagen, permitiendo que el modelo aprenda invariancias sin utilizar etiquetas. Estas transformaciones incluyen recortes aleatorios, ligeras rotaciones, inversión horizontal y cambios controlados en brillo o contraste. Todas estas operaciones están alineadas con el enfoque contrastivo implementado en el proyecto y buscan reforzar la robustez del modelo ante variaciones espaciales comunes en secuencias de marcha. Estas augmentaciones se aplican exclusivamente durante el pre-entrenamiento autosupervisado, mientras que la fase supervisada utiliza únicamente las transformaciones estándar.

\subsection{Construcción de Mini-Batches}

Durante el entrenamiento supervisado, el proyecto utiliza dos estrategias de muestreo complementarias. Para la parte basada en entropía cruzada, se emplea muestreo aleatorio tradicional. Por otro lado, para optimizar el \textit{Triplet Loss}, el modelo puede apoyarse en un esquema tipo PK Sampler, en el que cada mini-batch contiene un número fijo de identidades distintas y varias imágenes por cada una de ellas. Esto facilitará la construcción de anclas, positivos y negativos dentro del mismo lote, mejorando la discriminación de los embeddings entre clases y dentro de la misma identidad. Esta combinación de estrategias permite un entrenamiento más estable y efectivo para el modelo híbrido.

\begin{comment}
\subsection{Pre-Procesamiento para la Extracción de Siluetas}

El pre-procesamiento es un paso crítico para garantizar que las entradas del modelo estén normalizadas y aisladas del ruido de fondo:
\begin{enumerate}
    \item \textbf{Segmentación Humana:} Extracción de siluetas binarias para aislar la figura del individuo en movimiento de cada cuadro (\cite{Zhang2024LowResolution}).
    \item \textbf{Normalización Espacial:} Las siluetas se reescalarán a una dimensión fija y se contran para estandarizar la entrada, mitigando variaciones de distancia \cite{Lee2023GaitParse}.
    \item \textbf{Normalización Temporal:} Se ajustarán las secuencias de video para que representen un ciclo de marcha completo con una longitud temporal fija $N$, minimizando el impacto de las variaciones de velocidad de caminata (\cite{Kovacevic2021SelfAttentionGait}).
\end{enumerate}

\subsection{Generación del Gait Energy Image (GEI)}

Para la evaluación de marcha, se generará el \textit{Gait Energy Image} (GEI). El GEI es una representación 2D que condensa la información dinámica de un ciclo de marcha 3D en una única imagen estática, resultando en una reducción significativa de los requisitos de almacenamiento y procesamiento, manteniendo la invarianza a la fase (\cite{Kovacevic2021SelfAttentionGait}).

El GEI ($G(x, y)$) se calculá como la media de las siluetas binarias normalizadas ($\mathcal{B}(x, y, t)$) a lo largo de un ciclo de $N$ cuadros:

\begin{equation}
    G(x, y) = \frac{1}{N} \sum_{t=1}^{N} \mathcal{B}(x, y, t)
\end{equation}
\end{comment}

\section{Entrenamiento y evaluación experimental}

El proceso experimental del proyecto se basa en un esquema de entrenamiento híbrido compuesto por  un pre-entrenamiento autosupervisado diseñado para aprender representaciones generales de marcha, seguido por un ajuste fino supervisado orientado a la re-identificación. Ambos procedimientos fueron implementados y evaluados sobre CASIA-B, respetando la estructura real del flujo de trabajo descrito en el código.

\subsection{Protocolo de entrenamiento híbrido}

\subsubsection{Fase I: Pre-entrenamiento auto-supervisado}
El \textit{backbone} de marcha será pre-entrenado en el dataset utilizando un \textit{framework} autosupervisado, adaptado para secuencias de marcha. El objetivo es que el modelo aprenda representaciones cinemáticas sin depender de etiquetas en primera instancia \cite{Huang2025PersonViT, Zheng2022PASS}.

\subsubsection{Fase II: Ajuste fino (\textit{Fine-Tuning}) supervisado}
Posteiormente se realiza el ajuste fino supervisado del modelo híbrido completo sobre los datos etiquetados de CASIA-B.

\begin{itemize}
    \item \textbf{Ajuste Fino Diferencial:} Para optimizar la transferencia de conocimiento, se implementará un protocolo de tasa de aprendizaje diferencial. Las capas pre-entrenadas del \textit{backbone} de marcha utilizarán una tasa de aprendizaje baja para preservar la robustez adquirida en SSL, mientras que las capas de clasificación y métrica de salida se entrenarán con una tasa más alta, promoviendo la especialización en la discriminación de identidad (\cite{Zheng2022PASS}).
    \item \textbf{Funciones de Pérdida:} Se utilizará una función de pérdida combinada de \textit{Identity Loss} (\textit{Cross-Entropy}) y \textit{Metric Loss} (\textit{Triplet Loss}) para asegurar una maximización tanto de la clasificación de identidad como de la separación métrica de las incrustaciones (\textit{embeddings}) en el espacio de características (\cite{Purish2023GaitRecognition}).
\end{itemize}


\section{Diseño experimental y métricas de evaluación}

El diseño experimental se basa en el protocolo estándar del dataset CASIA-B, separando las secuencias en un conjunto \textit{gallery} y un conjunto de prueba según las variaciones de vista y condiciones de vestimenta. Para cada identidad, el modelo genera un vector de características (\textit{embedding}) mediante el \textit{backbone} entrenado, y luego se calcula la matriz completa de distancias euclidianas entre las muestras de ambos conjuntos. Este procedimiento permite evaluar la capacidad del modelo para recuperar correctamente la identidad de una persona bajo cambios de apariencia, vista o carga.

Las métricas empleadas reflejan los más comúnes en \textit{Gait Recognition}. \textit{Rank-1 Accuracy} cuantifica el porcentaje de veces en que la muestra correcta aparece como la más cercana en el espacio de características, siendo una medida directa de la precisión de re-identificación. Complementariamente, se utiliza el \textit{Mean Average Precision} (mAP), que evalúa la calidad del ordenamiento completo de las distancias, penalizando recuperaciones parciales y ofreciendo una visión más robusta del rendimiento general del modelo.

\begin{comment}
\begin{itemize}
    \item \textbf{Prueba de Covariantes:} La evaluación se enfocará en el rendimiento bajo las condiciones de caminata normal y con Ropa cambiada, todas en régimen de vista cruzada (\textit{cross-view}) (\cite{Li2020SemiSupGait}).
    \item \textbf{Control de Generalización:} Se utilizará un conjunto de desarrollo extraído de la distribución de los \textit{IDs} de prueba para monitorear el sobreajuste durante el \textit{fine-tuning} y asegurar que los resultados de la evaluación final sean una medida no sesgada de la generalización del modelo (\cite{Huang2025PersonViT, Zhang2024LowResolution}).
\end{itemize}

Además, se propone el uso de las siguientes métricas para poder cuantificar la eficiencia del modelo híbrido.
\begin{itemize}
    \item \textbf{Rank-1 Accuracy:} Mide la tasa de acierto en la cual la identidad correcta es clasificada como la primera coincidencia (Top-1) (\cite{Asperti2024ReviewReID})
    \item \textbf{mAP (\textit{Mean Average Precision}):} Evalúa el rendimiento del sistema de recuperación en el conjunto de la Galería, reflejando la calidad general de los resultados (\cite{Asperti2024ReviewReID}).
\end{itemize}
\end{comment}