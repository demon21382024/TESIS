\chapter{MARCO METODOLÓGICO}

% \noindent
% \setlength{\parindent}{1.25cm} % Asegura la sangría de 1.25 cm en el primer párrafo del capítulo

La metodología propuesta se enmarca específicamente en la re-identificación de personas basada en la marcha (\textit{Gait Recognition}). Se adoptará un enfoque híbrido que combina el aprendizaje auto-supervisado (SSL) y el aprendizaje supervisado, mediante \textit{Fine-Tuning}, para desarrollar un modelo robusto y generalizable, capaz de superar las limitaciones inherentes a la variabilidad de la apariencia y la escasez de datos etiquetados en escenarios de videovigilancia (\cite{Huang2025PersonViT, Lee2023GaitParse}).

Este enfoque metodológico se divide rigurosamente en tres áreas principales: La justificación y el diseño arquitectónico de la fusión \textit{Multi-Modal}, el protocolo de pre-procesamiento de datos de marcha, y la estrategia de entrenamiento híbrido; culminando en un diseño experimental detallado para la validación y el análisis de ablación.

\section{Diseño híbrido y arquitectura \textit{Multi-Modal}}

La estrategia de doble etapa es el pilar de este trabajo. Se justifica al considerar que el entrenamiento de modelos requieren un volumen de datos masivo para aprender representaciones robustas, una necesidad que la anotación manual supervisada no puede satisfacer eficientemente (\cite{Huang2025PersonViT, Lee2023GaitParse}).


\section{Fase I: Fundación del Conocimiento – Preentrenamiento Auto-Supervisado (SSL) a Gran Escala}

La primera fase de la metodología se sustenta en el \textit{Aprendizaje Auto-Supervisado} (\textit{Self-Supervised Learning}, SSL). Este paradigma elimina la dependencia de etiquetas humanas al generar su propia señal de supervisión a partir de la estructura intrínseca de los datos. El propósito de esta fase no es resolver la tarea final, sino construir un \textit{modelo base} (\textit{backbone}) capaz de desarrollar una comprensión profunda y generalizable de las características visuales relevantes.  

El proceso se basa en la formulación de \textit{tareas de supervisión derivadas directamente de los datos}, las cuales, de acuerdo con la literatura especializada en visión por computador, pueden clasificarse en dos enfoques metodológicos principales:

\subsection{Enfoques Generativos (Reconstructivos)}

Este grupo de métodos se fundamenta en el principio de \textit{aprender prediciendo lo oculto}. Modelos como el \textit{Modelado de Imágenes Enmascaradas} (MIM) o su versión temporal, el \textit{Modelado de Secuencias Enmascaradas} (MSM), representan ejemplos característicos de este enfoque.  

En un contexto de \textit{reidentificación basada en la marcha} (\textit{Gait Re-ID}), el modelo no recibe la secuencia completa de siluetas. En su lugar, se le presenta una secuencia en la que ciertos fotogramas o parches se encuentran enmascarados aleatoriamente, y su tarea consiste en reconstruir las partes ausentes.  

La justificación metodológica de este enfoque radica en que, para reconstruir correctamente una porción faltante de un ciclo de caminata, el modelo debe aprender la estructura latente del movimiento humano, las relaciones espaciales entre las articulaciones y la dinámica temporal del desplazamiento. Este proceso impulsa al modelo a desarrollar \textit{representaciones locales y de alta resolución}, que capturan la estructura esencial del fenómeno analizado.  

\subsection{Enfoques Discriminativos (Contrastivos)}

Esta familia de métodos, ampliamente difundida por marcos como \textit{MoCo} y \textit{SimCLR}, se basa en el principio de \textit{aprender mediante comparación}. En lugar de reconstruir, el modelo de \textit{Aprendizaje Contrastivo} (\textit{Contrastive Learning}, CL) aprende a identificar qué vistas provienen de la misma instancia y cuáles no.  

Durante el entrenamiento, el modelo maximiza la similitud en el espacio de características entre dos vistas aumentadas de una misma imagen (denominadas \textit{pares positivos}) y, simultáneamente, minimiza la similitud con las demás imágenes del conjunto (los \textit{pares negativos}).  

El objetivo metodológico de este enfoque es fomentar el \textit{aprendizaje de invariancias}, de modo que el modelo genere representaciones robustas frente a transformaciones superficiales tales como ruido, recortes o cambios de iluminación, preservando únicamente la identidad semántica de cada instancia.  

La \textbf{selección entre un enfoque generativo (MIM) o discriminativo (CL)} constituye una decisión metodológica fundamental, ya que determina el tipo de sesgo inductivo introducido en el modelo.  
\begin{itemize}
    \item Los métodos contrastivos priorizan el aprendizaje de características distintivas, lo que resulta adecuado para tareas de \textit{reidentificación basada en la apariencia}.
    \item Los métodos generativos promueven la comprensión de estructuras comunes, lo cual es más apropiado para la \textit{reidentificación basada en la marcha (Gait Re-ID)}, donde la dinámica del movimiento actúa como la firma biométrica principal.
\end{itemize}

El \textbf{resultado de la Fase I} no es un modelo finalizado, sino un \textit{modelo base preentrenado} con pesos inicializados que capturan conocimiento visual relevante para el dominio. Esta inicialización supera ampliamente a una aleatoria o incluso a un preentrenamiento convencional en \textit{ImageNet}, proporcionando mayor eficiencia de entrenamiento y mejor capacidad de generalización, además de ayudar al modelo a evitar mínimos locales poco representativos en las fases posteriores.  

\section{Fase II: Especialización de la Tarea – Ajuste Fino (Fine-Tuning) Supervisado}

Una vez que el modelo ha adquirido una comprensión general de la forma y el movimiento a través del preentrenamiento auto-supervisado, se procede a su especialización en la \textit{tarea específica (downstream task)} de reidentificación. En esta fase, se incorporan los \textit{datos etiquetados}, los cuales tienen un costo más elevado, con el propósito de desarrollar la capacidad discriminativa del modelo.  

A diferencia de un problema de clasificación tradicional, el objetivo principal de esta fase es el \textit{aprendizaje métrico (metric learning)}, cuyo propósito es construir un \textit{espacio de características (feature space)} altamente discriminativo. En dicho espacio, las representaciones correspondientes a una misma identidad (intra-clase) deben agruparse de manera compacta, mientras que las representaciones de distintas identidades (inter-clase) deben mantenerse lo más separadas posible.  

El problema de reidentificación presenta una naturaleza dual: requiere gestionar una \textit{alta variabilidad intra-clase} (una misma persona puede variar en apariencia según el ángulo, la ropa o las condiciones de iluminación) y, al mismo tiempo, una \textit{baja variabilidad inter-clase} (distintas personas pueden parecerse entre sí). Para abordar esta dualidad, se emplea una \textit{estrategia de pérdidas híbridas}, compuesta por dos funciones complementarias:

\begin{itemize}
    \item \textbf{Pérdida de Identidad (Identity Loss):} Habitualmente implementada mediante \textit{Entropía Cruzada (Cross-Entropy Loss)}. Este componente considera la tarea como un problema de clasificación y promueve la coherencia de las representaciones intra-clase al agrupar todas las instancias de una misma identidad en una única representación consistente.
    
    \item \textbf{Pérdida Métrica (Metric Loss):} Generalmente implementada mediante \textit{Triplet Loss} o \textit{Contrastive Loss}. Esta función impone explícitamente un margen de separación entre identidades, penalizando al modelo cuando la distancia entre una muestra ancla y su correspondiente positivo no es significativamente menor que la distancia al negativo.
\end{itemize}

No obstante, este proceso de especialización conlleva un riesgo metodológico conocido como \textit{olvido catastrófico}, que ocurre cuando el reajuste excesivo sobre los nuevos datos etiquetados deteriora la robustez y la capacidad general adquiridas en la fase anterior.  

Para mitigar este efecto, se aplica la técnica de \textit{Ajuste Fino Diferencial (Differential Fine-Tuning)}, que sustituye la tasa de aprendizaje uniforme por un esquema \textit{asimétrico}, considerando la distinta naturaleza de los componentes del modelo:  

\begin{itemize}
    \item \textbf{Modelo Base (heredado de la Fase I):} Incluye las capas previamente entrenadas que contienen conocimiento estructural y dinámico. A este componente se le asigna una tasa de aprendizaje reducida, con el fin de preservar la robustez adquirida y permitir ajustes graduales sin comprometer la generalización.

    \item \textbf{Cabeza de Clasificación (introducida en la Fase II):} Comprende las capas añadidas para la clasificación de identidad o la proyección métrica. Dado que estas capas se inicializan desde cero, se les asigna una tasa de aprendizaje más alta, permitiendo una rápida adaptación a la tarea supervisada de identificación.
\end{itemize}

\begin{comment}
\subsection{Estructura del modelo de fusión textit{Multi-Modal} }

El modelo implementa una arquitectura de doble rama y \textbf{Fusión a Nivel de Característica} (\textit{Feature-Level Fusion}) para explotar la complementariedad de las biometrías de apariencia y marcha. \cite{Purish2023GaitRecognition, Rao2024MSFFT}

\begin{itemize}
    \item \textbf{Rama de Marcha ($\vec{F_g}$):} Emplea un \textit{backbone} de Vision Transformer (ViT) o 3D Local CNN, pre-entrenado con SSL, para extraer las características cinemáticas. \cite{Purish2023GaitRecognition, Rao2024MSFFT}
    \item \textbf{Rama de Apariencia ($\vec{F_a}$):} Utiliza un extractor de características 2D (e.g., ResNet-50) para capturar señales visuales a corto plazo. 
    \item \textbf{Módulo de Fusión:} Combina las características mediante la **Concatenación Ponderada**, la cual ha demostrado ser efectiva para integrar información correlacionada. \cite{Rao2024MSFFT} La fórmula conceptual para el vector de característica final ($\vec{F}$) es:
    $$\vec{F} = [\vec{F_a}, \theta \cdot \vec{F_g}]$$
    El hiperparámetro $\theta$ se utiliza para aumentar el peso de la característica de marcha ($\vec{F_g}$), haciendo el sistema más robusto ante la variación de la vestimenta (condición CL), donde la información de apariencia falla. \cite{Zhou2024VersReID, Rao2024MSFFT}
\end{itemize}
\end{comment}

\section{Adquisición y pre-procesamiento de datos}

\subsection{Selección y Uso de Bases de Datos Benchmark}

Se proponen las siguientes bases de datos por su relevancia en la literatura revisada y su cobertura de las variantes clave:

\begin{table}[h]
    \centering
    \caption{Selección de Bases de Datos y Uso Metodológico}
    \label{tab:datasets}
    \begin{tabular}{l|p{3.5cm}|p{5cm}}
        \toprule
        \textbf{Dataset} & \textbf{Propósito Metodológico} & \textbf{Covariantes Clave} \\
        \midrule
        OU-MVLP ($>10,000$ IDs) & Fase I: Pre-entrenamiento Auto-Supervisado (SSL) \cite{Huang2025PersonViT} & Multi-View \\
        CASIA-B (124 IDs) & Fase II: Ajuste Fino Supervisado y Evaluación Final \cite{Li2020SemiSupGait} & Ropa (CL), Carga (BG), Multi-View \\
        TUM-GAID & Validación complementaria de generalización \cite{Purish2023GaitRecognition} & Dirección de Caminata \cite{Han2021LocalitySGE} \\
        \bottomrule
    \end{tabular}
\end{table}

\subsection{Pre-Procesamiento para la Extracción de Siluetas}

El pre-procesamiento es un paso crítico para garantizar que las entradas del modelo estén normalizadas y aisladas del ruido de fondo:
\begin{enumerate}
    \item \textbf{Segmentación Humana:} Extracción de siluetas binarias para aislar la figura del individuo en movimiento de cada cuadro (\cite{Zhang2024LowResolution}).
    \item \textbf{Normalización Espacial:} Las siluetas se reescalarán a una dimensión fija y se contran para estandarizar la entrada, mitigando variaciones de distancia \cite{Lee2023GaitParse}.
    \item \textbf{Normalización Temporal:} Se ajustarán las secuencias de video para que representen un ciclo de marcha completo con una longitud temporal fija $N$, minimizando el impacto de las variaciones de velocidad de caminata (\cite{Kovacevic2021SelfAttentionGait}).
\end{enumerate}

\subsection{Generación del Gait Energy Image (GEI)}

Para la evaluación de marcha, se generará el \textit{Gait Energy Image} (GEI). El GEI es una representación 2D que condensa la información dinámica de un ciclo de marcha 3D en una única imagen estática, resultando en una reducción significativa de los requisitos de almacenamiento y procesamiento, manteniendo la invarianza a la fase (\cite{Kovacevic2021SelfAttentionGait}).

El GEI ($G(x, y)$) se calculá como la media de las siluetas binarias normalizadas ($\mathcal{B}(x, y, t)$) a lo largo de un ciclo de $N$ cuadros:

\begin{equation}
    G(x, y) = \frac{1}{N} \sum_{t=1}^{N} \mathcal{B}(x, y, t)
\end{equation}

\section{Entrenamiento y evaluación experimental}

\subsection{Protocolo de entrenamiento híbrido}

\subsubsection{Fase I: Pre-entrenamiento auto-supervisado}
El \textit{backbone} de marcha será pre-entrenado en el dataset utilizando un \textit{framework} autosupervisado, adaptado para secuencias de marcha. El objetivo es que el modelo aprenda representaciones cinemáticas sin depender de etiquetas en primera instancia \cite{Huang2025PersonViT, Zheng2022PASS}.

\subsubsection{Fase II: Ajuste fino (\textit{Fine-Tuning}) supervisado}
Posteiormente se realiza el ajuste fino supervisado del modelo híbrido completo sobre los datos etiquetados de CASIA-B.

\begin{itemize}
    \item \textbf{Ajuste Fino Diferencial:} Para optimizar la transferencia de conocimiento, se implementará un protocolo de tasa de aprendizaje diferencial. Las capas pre-entrenadas del \textit{backbone} de marcha utilizarán una tasa de aprendizaje baja para preservar la robustez adquirida en SSL, mientras que las capas de clasificación y métrica de salida se entrenarán con una tasa más alta, promoviendo la especialización en la discriminación de identidad (\cite{Zheng2022PASS}).
    \item \textbf{Funciones de Pérdida:} Se utilizará una función de pérdida combinada de \textit{Identity Loss} (\textit{Cross-Entropy}) y \textit{Metric Loss} (\textit{Triplet Loss}) para asegurar una maximización tanto de la clasificación de identidad como de la separación métrica de las incrustaciones (\textit{embeddings}) en el espacio de características (\cite{Purish2023GaitRecognition}).
\end{itemize}

\subsection{Diseño experimental y métricas de evaluación}

\begin{itemize}
    \item \textbf{Prueba de Covariantes:} La evaluación se enfocará en el rendimiento bajo las condiciones de caminata normal y con Ropa cambiada, todas en régimen de vista cruzada (\textit{cross-view}) (\cite{Li2020SemiSupGait}).
    \item \textbf{Control de Generalización:} Se utilizará un conjunto de desarrollo extraído de la distribución de los \textit{IDs} de prueba para monitorear el sobreajuste durante el \textit{fine-tuning} y asegurar que los resultados de la evaluación final sean una medida no sesgada de la generalización del modelo (\cite{Huang2025PersonViT, Zhang2024LowResolution}).
\end{itemize}

Además, se propone el uso de las siguientes métricas para poder cuantificar la eficiencia del modelo híbrido.
\begin{itemize}
    \item \textbf{Rank-1 Accuracy:} Mide la tasa de acierto en la cual la identidad correcta es clasificada como la primera coincidencia (Top-1) (\cite{Asperti2024ReviewReID})
    \item \textbf{mAP (\textit{Mean Average Precision}):} Evalúa el rendimiento del sistema de recuperación en el conjunto de la Galería, reflejando la calidad general de los resultados (\cite{Asperti2024ReviewReID}).
\end{itemize}

\begin{comment}
\subsection{Análisis de Ablación Propuesto}
Para validar las decisiones metodológicas, se realizará un análisis de ablación sistemático:
\begin{enumerate}
    \item \textbf{Ablación I: Fusión Multi-Modal} (Comparación $\vec{F}$ vs. $\vec{F_g}$ o $\vec{F_a}$ solamente).
    \item \textbf{Ablación II: Impacto del SSL} (Comparación \textbf{SSL + Fine-Tuning} vs. Supervisado desde cero).
    \item \textbf{Ablación III: Optimización de Ponderación $\theta$} (Determinación del valor óptimo de $\theta$ para la robustez en la condición CL).
\end{enumerate}
\end{comment}